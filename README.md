# An ai tools website uses OpenAi Api ~ and now it can be ran locally using LM Studio (Updated)
## Added Streaming for ChatGPT, so you can see responses as they come in
## Converted the app from js to ts
## UI Improvements
# Get Started
### 1. Clone the repository:
```bash
git clone https://github.com/UGoingNoWhereBoy/Vi-Ai
```
### 2. CD into the repository
```bash
  cd Vi-Ai
```
### 3. Install packages 
```bash
npm install
```
### 4. Create a .env file and fill it with your own api key from openai
```bash
touch .env
```
### 5. Run the app 
```bash
npm run dev
```
### 6. Give it a star

# Run it locally 
## Install LM Studio : https://lmstudio.ai/
## Install a model
## choose local server and start it make sure the port is 1234
## Now go to the browser open the server you're runing vi-ai on (localhost:3000) and start chatting free of cost and unlimted :)

# Notes 
##  for lower end devices with 6GB Gpu vram or lower 8-16GB Ram 6c cpu's use 3B-13B models to get responses faster
## if you try to use a big model on a low device it will take hours to generate a single word.

# ![image](https://github.com/UGoingNoWhereBoy/Vi-Ai/assets/103299832/3bc4627f-e9c7-4924-99f0-e97df3212a5c)
# Visit it here https://vi-ai.vercel.app/

## with the help of vercel edge functions https://vercel.com/blog/gpt-3-app-next-js-vercel-edge-functions
